\subsection{}

\begin{figure}[htbp]
    \label{P}
    \centering
    $\mathbf{P}$ = 
            \begin{blockarray}{c@{\hspace{1pt}}rrr@{\hspace{3pt}}}
             & 0   & 1   & 2 \\
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            0 & 0.5  & 0.35 & 0.15 \\
            1 & 0.1  & 0.75 & 0.15 \\
            2 & 0.0 5& 0.6  & 0.35   \\
            \end{block}
        \end{blockarray}
\end{figure}
The probability of remaining in state 1 for two consecutive days is given by, $P(X_2=1,X_1=1|X_0=1)=P(X_2 = 1 | X_1 = 1) \cdot P(X_1 = 1 | X_0 = 1) = P_{11} \cdot P_{11} = 0.75^2 = 0.5625$. This follows from the Markov property which states that the state of $X_{n+1}$ depends only on $X_{n}$.

The probability of the air quality being poor the day after tomorrow can be expressed as $P(X_2 = 1|X_0 = 1)$. The matrix of the two - step transition probabilities is given by $\mathbf{P}^{2} = \mathbf{P}^{(1+1)} = \mathbf{P}^{(1)} \cdot  \mathbf{P}^{(1)}$. The matrix multiplication gives us the following matrix, and the probability of returning to state 1 after two steps is simply $P^{2}_{11} = 0.6875$

\begin{figure}[htbp]
    \label{Psquared}
    \centering
    $\mathbf{P}^2$ = 
            \begin{blockarray}{c@{\hspace{1pt}}rrr@{\hspace{3pt}}}
             & 0   & 1   & 2 \\
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            0 & 0.2925 & 0.5275 & 0.18 \\
            1 & 0.1325 & 0.6875 & 0.18 \\
            2 & 0.1025 & 0.6775 & 0.22   \\
            \end{block}
        \end{blockarray}
\end{figure}

The long - run distribution of the Markov chain be obtained by solving the following set of equations:

\begin{equation}
    \pi_0 = \pi_0\cdot\frac{1}{2} + \pi_1\cdot\frac{1}{10} + \pi_2\cdot\frac{1}{20}
\end{equation}

\begin{equation}
    \pi_1 = \pi_0\cdot\frac{7}{20} + \pi_1\cdot\frac{3}{4} + \pi_2\cdot\frac{3}{5}
\end{equation}

\begin{equation}
    \pi_2 = \pi_0\cdot\frac{3}{20} + \pi_1\cdot\frac{3}{20} + \pi_2\cdot\frac{7}{20}
\end{equation}

\begin{equation}
    \pi_0  + \pi_1 + \pi_2 = 1
\end{equation}


Solving these equations leads to the following results: $\pi_0 = \frac{29}{192} \approx 0.1510$, $\pi_1 = \frac{127}{192} \approx 0.6615$, $\pi_2 = \frac{3}{16} \approx 0.1875$

\subsection{}

<<cache=TRUE, plot1, fig.cap = "Simulated long - run distribution of the Markov chain" >>=

P <- matrix(data=c(0.5,0.1,0.05,0.35,0.75,0.6,0.15,0.15,0.35), nrow= 3)
lrd <- c(0,0,0)
state <- 2
N <- 100000

for (i in 1:N){
  p <- runif(1)
  if (p < P[state,1]){
    state <- 1
  } else if (p < P[state,1] + P[state,2]){
      state <- 2
  } else {
    state <- 3
  }
  lrd[state] <- lrd[state] + 1
}

barplot(lrd/N, main="Long - run distribution",xlab="State",
ylab="Count",names.arg = c('0','1','2'))

lrd/N

@

The proportion of time the simulated Markov chain has very poor air quality is given graphically by figure \ref{fig:plot1} and the numerical value was the first value printed in the code block above, \ref{lrd}, and is very close to the theoretical value for the long - run disitribution. 


The number of steps used when simulating the chain will influence how well the simulated value agrees with the theoretical answer. We should find that simulated distribution gets closer to the theoretical distribution as the number of steps increases, and this seems to be the case. From looking at figure \ref{fig:plot1}, or the printed vector we see that, when using many steps, the simulated results are approaching the theoretical results. 



The long - run distributions dependency on the initial state seems to decrease as the number of steps increases.

We plot three different graphs representing the proportion of time spent in state 0 for increasing N. The dependency on the inital state clearly gets smaller as N increases. 

<<cache=TRUE>>=

getlrd <- function(P, state, N){
  lrd <- c(0,0,0)
  
  for (i in 1:N){
    p <- runif(1)
    if (p < P[state,1]){
      state <- 1
    } else if (p < P[state,1] + P[state,2]){
      state <- 2
    } else {
      state <- 3
    }
    lrd[state] <- lrd[state] + 1
  }
  return(lrd/N)
}

P <- matrix(data=c(0.5,0.1,0.05,0.35,0.75,0.6,0.15,0.15,0.35), nrow= 3)

xaxis <- seq(10,700,10)
avlrd <- matrix(data = 0, nrow = 3, ncol = length(xaxis))
k <- 1

for (i in xaxis){
  for (j in 1:100){
    lrd <- getlrd(P,1,i)
    avlrd[1,k] <- avlrd[1,k] + lrd[1]/100
    lrd <- getlrd(P,2,i)
    avlrd[2,k] <- avlrd[2,k] + lrd[1]/100
    lrd <- getlrd(P,3,i)
    avlrd[3,k] <- avlrd[3,k] + lrd[1]/100
  }
  k <- k + 1
}

plot(xaxis,avlrd[1,],type="n",main=
"Dependency on initial state",xlab="Number of steps",ylab=
"Proportion of time spent in state 0")
lines(xaxis,avlrd[1,],col="black",lwd=1.5)
lines(xaxis,avlrd[2,],col="blue",lwd=1.5)
lines(xaxis,avlrd[3,],col="red",lwd=1.5)
legend(125,0.20,c("Initial state = 0","Inital state = 1", "Inital state =2"),
lty = c(1,1,1),lwd=c(1.5,1.5,1.5),col=c("black","blue","red"))

@

\subsection{}

\begin{figure}[htbp]
    \label{P}
    \centering
    $\mathbf{P} = 
            \begin{blockarray}{c@{\hspace{1pt}}rrrr@{\hspace{3pt}}}
             & 0   & 1   & 2   & 3   \\
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rrrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            0 & 1 & 0 & 0 & 0 \\
            1 & 0.05 & 0.85 & 0.1 & 0 \\
            2 & 0   & 0.05   & 0.65 & 0.3   \\
            3 & 0 & 0 & 0 & 1 \\
            \end{block}
        \end{blockarray}$
\end{figure}

The chance of the patient becoming functional when starting out in state 1 is given by the following expression:

\begin{equation}
    P(Patient\ becomes\ functional) = (\sum_{n=1}^{\infty}P_{03}{\cdot}P_{10}^{n} + P_{13}{\cdot}P_{11}^{n} + P_{23}{\cdot}P_{12}^{n}  + P_{33}{\cdot}P_{13}^{n}) + P_{13}
\end{equation}

Since $P_{03}$, $P_{13}$ and $P_{33}$ are all equal to zero,  we get

\begin{equation}
    P_{23}{\cdot}\sum_{n=1}^{\infty}P_{12}^{n} = 0.3 \cdot \sum_{n=1}^{\infty}0.1^{n} = 0.3 \cdot \frac{0.1}{1 - 0.1} = \frac{3}{10} \cdot \frac{1}{9} = \frac{1}{30}
\end{equation}

The transition matrix can be reorganized so that it is of the following form

\begin{figure}[htbp]
    \label{P}
    \centering
    $\mathbf{P} = 
            \begin{blockarray}{c@{\hspace{1pt}}rrrr@{\hspace{3pt}}}
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            & Q &  R \\
            & 0 & I  \\
            \end{block}
        \end{blockarray}$
\end{figure}

with Q representing the matrix that describes steps between transient states and R representing the matrix that describes steps between transient and absorbing states. With at least one absorbing state we also get the identity matrix $I$ and a null matrix. 

We want to find the expected amount of steps before we enter one of the two absorbing steps. We approach this problem by looking at the fundamental matrix N given by


\begin{equation}
    N = \sum_{n=1}^{\infty}Q^{n} = (I - Q)^{-1}
\end{equation}

We get the matrix 

\begin{figure}[htbp]
    \label{P}
    \centering
    $\mathbf{P} = 
            \begin{blockarray}{c@{\hspace{1pt}}rrrr@{\hspace{3pt}}}
             & 1   & 2   & 0   & 3   \\
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rrrr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            1 & 0.85 & 0.1 & 0.05 & 0 \\
            2 & 0.05 & 0.65 & 0 & 0.3 \\
            0 & 0   & 0   & 1 & 0   \\
            3 & 0 & 0 & 0 & 1 \\
            \end{block}
        \end{blockarray}$
\end{figure}

with 

\begin{figure}[htbp]
    \label{Q}
    \centering
    $\mathbf{Q} = 
            \begin{blockarray}{c@{\hspace{1pt}}rrrr@{\hspace{3pt}}}
            \begin{block}{r@{\hspace{1pt}}|@{\hspace{1pt}}
        |@{\hspace{1pt}}rr@{\hspace{1pt}}|@{\hspace{1pt}}|}
            & 0.85 &  0.1 \\
            & 0.05 & 0.65  \\
            \end{block}
        \end{blockarray}$
\end{figure}

the expected number of steps is given by the first element in $t = N1$ with N being the fundamental matrix and 1 being a column vector of size t and entries all 1. 


<<>>=
Q <- matrix(data=c(0.85, 0.05,0.1,0.65), nrow = 2)
I <- diag(2)
N <- solve(I-Q)
t <- N%*%matrix(data=c(1,1),ncol=1)
t[1]
@

\subsection{}

The expecected number of steps is 9.47

<<cache = TRUE>>=
P <- matrix(data = c(1,0.05,0,0,0,0.85,0.05,0,0,0.1,0.65,0,0,0,0.3,1),nrow =4)
state <- 2
N <- 0
avabsorb <- 0

for (i in 1:1000){
  while ((state != 1)&&(state != 4)){
    p <- runif(1)
    if (p < P[state,1]){
      state <- 1
    } else if (p < (P[state,1] + P[state,2])){
      state <- 2
    } else if (p < (P[state,1] + P[state,2] + P[state,3])){
      state <- 3
    } else {
      state <- 4
    }
    N <- N + 1
  }
  avabsorb <- avabsorb + N/1000
  N <- 0
  state <- 2
}

avabsorb

@

When simulating the Markov chain 50 times we observe that the amount of steps before entering an absorbing state can differ from the expected value. 

<<cache=TRUE>>=

P <- matrix(data = c(1,0.05,0,0,0,0.85,0.05,0,0,0.1,0.65,0,0,0,0.3,1),nrow =4)
state <- 2
N <- 0
avabsorb <- 0
Nvec <- numeric(50)
xaxis <- seq(1,50,1)

for (i in 1:50){
  while ((state != 1)&&(state != 4)){
    p <- runif(1)
    if (p < P[state,1]){
      state <- 1
    } else if (p < (P[state,1] + P[state,2])){
      state <- 2
    } else if (p < (P[state,1] + P[state,2] + P[state,3])){
      state <- 3
    } else {
      state <- 4
    }
    N <- N + 1
  }
  Nvec[i] <- N
  N <- 0
  state <- 2
}

plot(xaxis,Nvec)

@



